{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dashstander/grokking-galois/blob/main/x%5Ey%2Bz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foH7-i3lhgS4",
        "outputId": "480c2f9b-b9d9-4232-8ef4-abbf9a85c251"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 449 kB/s \n",
            "\u001b[?25hCollecting polars\n",
            "  Downloading polars-0.15.7-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.6 MB 8.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from polars) (4.4.0)\n",
            "Installing collected packages: polars, einops\n",
            "Successfully installed einops-0.6.0 polars-0.15.7\n"
          ]
        }
      ],
      "source": [
        "! pip install einops polars tqdm"
      ],
      "id": "foH7-i3lhgS4"
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install git+https://github.com/neelnanda-io/TransformerLens.git@new-demo\n",
        "# Install another version of node that makes PySvelte work way faster\n",
        "!curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n",
        "%pip install git+https://github.com/neelnanda-io/PySvelte.git"
      ],
      "metadata": {
        "id": "lWVvy7pYgHPZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a221eb7-abf1-4d40-b2f4-351b77bd3ed4"
      },
      "id": "lWVvy7pYgHPZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/neelnanda-io/TransformerLens.git@new-demo\n",
            "  Cloning https://github.com/neelnanda-io/TransformerLens.git (to revision new-demo) to /tmp/pip-req-build-8x4kjn0a\n",
            "  Running command git clone -q https://github.com/neelnanda-io/TransformerLens.git /tmp/pip-req-build-8x4kjn0a\n",
            "  Running command git checkout -b new-demo --track origin/new-demo\n",
            "  Switched to a new branch 'new-demo'\n",
            "  Branch 'new-demo' set up to track remote branch 'new-demo' from 'origin'.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fancy-einsum<0.0.4,>=0.0.3\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.21 in /usr/local/lib/python3.8/dist-packages (from transformer-lens==0.2.0) (1.21.6)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.1.5 in /usr/local/lib/python3.8/dist-packages (from transformer-lens==0.2.0) (1.3.5)\n",
            "Collecting datasets<3.0.0,>=2.7.1\n",
            "  Downloading datasets-2.8.0-py3-none-any.whl (452 kB)\n",
            "\u001b[K     |████████████████████████████████| 452 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting torchtyping<0.2.0,>=0.1.4\n",
            "  Downloading torchtyping-0.1.4-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: torch<2.0,>=1.10 in /usr/local/lib/python3.8/dist-packages (from transformer-lens==0.2.0) (1.13.0+cu116)\n",
            "Collecting wandb<0.14.0,>=0.13.5\n",
            "  Downloading wandb-0.13.7-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 67.4 MB/s \n",
            "\u001b[?25hCollecting rich<13.0.0,>=12.6.0\n",
            "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 71.2 MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=4.25.1\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 50.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.64.1 in /usr/local/lib/python3.8/dist-packages (from transformer-lens==0.2.0) (4.64.1)\n",
            "Requirement already satisfied: einops<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from transformer-lens==0.2.0) (0.6.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (9.0.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (21.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (3.8.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (2.23.0)\n",
            "Collecting huggingface-hub<1.0.0,>=0.2.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 66.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (2022.11.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 82.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (0.3.6)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 80.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (6.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (22.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (6.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (2.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (3.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas<2.0.0,>=1.1.5->transformer-lens==0.2.0) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas<2.0.0,>=1.1.5->transformer-lens==0.2.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas<2.0.0,>=1.1.5->transformer-lens==0.2.0) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.7.1->transformer-lens==0.2.0) (3.0.4)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 78.7 MB/s \n",
            "\u001b[?25hCollecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from rich<13.0.0,>=12.6.0->transformer-lens==0.2.0) (2.6.1)\n",
            "Collecting typeguard>=2.11.1\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 67.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.25.1->transformer-lens==0.2.0) (2022.6.2)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.8/dist-packages (from wandb<0.14.0,>=0.13.5->transformer-lens==0.2.0) (2.3)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb<0.14.0,>=0.13.5->transformer-lens==0.2.0) (3.19.6)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb<0.14.0,>=0.13.5->transformer-lens==0.2.0) (7.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb<0.14.0,>=0.13.5->transformer-lens==0.2.0) (57.4.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.12.1-py2.py3-none-any.whl (174 kB)\n",
            "\u001b[K     |████████████████████████████████| 174 kB 80.3 MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb<0.14.0,>=0.13.5->transformer-lens==0.2.0) (5.4.8)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 75.9 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.12.0-py2.py3-none-any.whl (173 kB)\n",
            "\u001b[K     |████████████████████████████████| 173 kB 79.5 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.11.1-py2.py3-none-any.whl (168 kB)\n",
            "\u001b[K     |████████████████████████████████| 168 kB 75.8 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.11.0-py2.py3-none-any.whl (168 kB)\n",
            "\u001b[K     |████████████████████████████████| 168 kB 101.2 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.10.1-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 59.8 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.10.0-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 72.8 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.10-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 75.0 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 64.7 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n",
            "\u001b[K     |████████████████████████████████| 158 kB 63.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 86.1 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 85.8 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 85.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 80.5 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 86.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 82.5 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 84.8 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 84.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: transformer-lens, pathtools\n",
            "  Building wheel for transformer-lens (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformer-lens: filename=transformer_lens-0.2.0-py3-none-any.whl size=67066 sha256=ffba11aefea70b00089c538612540cc3bf0919d045960c142c7d0dca1ec38f17\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6w0jyzd6/wheels/82/d1/c7/e1856bcf4639877dd69f7b2d3765428c0af94b8f186b064c38\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=42e809b45a7015881b13c03fa56436338c646896687d87127d1d2266bcc21211\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "Successfully built transformer-lens pathtools\n",
            "Installing collected packages: urllib3, smmap, gitdb, xxhash, typeguard, tokenizers, shortuuid, setproctitle, sentry-sdk, responses, pathtools, multiprocess, huggingface-hub, GitPython, docker-pycreds, commonmark, wandb, transformers, torchtyping, rich, fancy-einsum, datasets, transformer-lens\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 2.7.1\n",
            "    Uninstalling typeguard-2.7.1:\n",
            "      Successfully uninstalled typeguard-2.7.1\n",
            "Successfully installed GitPython-3.1.29 commonmark-0.9.1 datasets-2.8.0 docker-pycreds-0.4.0 fancy-einsum-0.0.3 gitdb-4.0.10 huggingface-hub-0.11.1 multiprocess-0.70.14 pathtools-0.1.2 responses-0.18.0 rich-12.6.0 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.11 smmap-5.0.0 tokenizers-0.13.2 torchtyping-0.1.4 transformer-lens-0.2.0 transformers-4.25.1 typeguard-2.13.3 urllib3-1.25.11 wandb-0.13.7 xxhash-3.1.0\n",
            "\n",
            "## Installing the NodeSource Node.js 16.x repo...\n",
            "\n",
            "\n",
            "## Populating apt-get cache...\n",
            "\n",
            "+ apt-get update\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,235 kB]\n",
            "Get:15 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,143 kB]\n",
            "Fetched 3,659 kB in 3s (1,462 kB/s)\n",
            "Reading package lists... Done\n",
            "\n",
            "## Confirming \"bionic\" is supported...\n",
            "\n",
            "+ curl -sLf -o /dev/null 'https://deb.nodesource.com/node_16.x/dists/bionic/Release'\n",
            "\n",
            "## Adding the NodeSource signing key to your keyring...\n",
            "\n",
            "+ curl -s https://deb.nodesource.com/gpgkey/nodesource.gpg.key | gpg --dearmor | tee /usr/share/keyrings/nodesource.gpg >/dev/null\n",
            "\n",
            "## Creating apt sources list file for the NodeSource Node.js 16.x repo...\n",
            "\n",
            "+ echo 'deb [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x bionic main' > /etc/apt/sources.list.d/nodesource.list\n",
            "+ echo 'deb-src [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x bionic main' >> /etc/apt/sources.list.d/nodesource.list\n",
            "\n",
            "## Running `apt-get update` for you...\n",
            "\n",
            "+ apt-get update\n",
            "Get:1 https://deb.nodesource.com/node_16.x bionic InRelease [4,584 B]\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Get:3 https://deb.nodesource.com/node_16.x bionic/main amd64 Packages [773 B]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 5,357 B in 1s (5,731 B/s)\n",
            "Reading package lists... Done\n",
            "\n",
            "## Run `\u001b[1msudo apt-get install -y nodejs\u001b[m` to install Node.js 16.x and npm\n",
            "## You may also need development tools to build native addons:\n",
            "     sudo apt-get install gcc g++ make\n",
            "## To install the Yarn package manager, run:\n",
            "     curl -sL https://dl.yarnpkg.com/debian/pubkey.gpg | gpg --dearmor | sudo tee /usr/share/keyrings/yarnkey.gpg >/dev/null\n",
            "     echo \"deb [signed-by=/usr/share/keyrings/yarnkey.gpg] https://dl.yarnpkg.com/debian stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list\n",
            "     sudo apt-get update && sudo apt-get install yarn\n",
            "\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  nodejs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 27.2 MB of archives.\n",
            "After this operation, 128 MB of additional disk space will be used.\n",
            "Get:1 https://deb.nodesource.com/node_16.x bionic/main amd64 nodejs amd64 16.19.0-deb-1nodesource1 [27.2 MB]\n",
            "Fetched 27.2 MB in 0s (62.1 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package nodejs.\n",
            "(Reading database ... 124016 files and directories currently installed.)\n",
            "Preparing to unpack .../nodejs_16.19.0-deb-1nodesource1_amd64.deb ...\n",
            "Unpacking nodejs (16.19.0-deb-1nodesource1) ...\n",
            "Setting up nodejs (16.19.0-deb-1nodesource1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/neelnanda-io/PySvelte.git\n",
            "  Cloning https://github.com/neelnanda-io/PySvelte.git to /tmp/pip-req-build-6e1yakpt\n",
            "  Running command git clone -q https://github.com/neelnanda-io/PySvelte.git /tmp/pip-req-build-6e1yakpt\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.8/dist-packages (from PySvelte==1.0.0) (0.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from PySvelte==1.0.0) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from PySvelte==1.0.0) (1.13.0+cu116)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (from PySvelte==1.0.0) (2.8.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (from PySvelte==1.0.0) (4.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from PySvelte==1.0.0) (4.64.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from PySvelte==1.0.0) (1.3.5)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.8/dist-packages (from PySvelte==1.0.0) (2.13.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets->PySvelte==1.0.0) (6.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets->PySvelte==1.0.0) (3.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets->PySvelte==1.0.0) (3.8.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets->PySvelte==1.0.0) (2.23.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets->PySvelte==1.0.0) (0.18.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets->PySvelte==1.0.0) (0.70.14)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets->PySvelte==1.0.0) (0.3.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets->PySvelte==1.0.0) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets->PySvelte==1.0.0) (0.11.1)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets->PySvelte==1.0.0) (9.0.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets->PySvelte==1.0.0) (2022.11.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (22.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (6.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (2.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets->PySvelte==1.0.0) (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets->PySvelte==1.0.0) (3.8.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets->PySvelte==1.0.0) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (1.25.11)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->PySvelte==1.0.0) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->PySvelte==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->PySvelte==1.0.0) (1.15.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers->PySvelte==1.0.0) (0.13.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers->PySvelte==1.0.0) (2022.6.2)\n",
            "Building wheels for collected packages: PySvelte\n",
            "  Building wheel for PySvelte (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PySvelte: filename=PySvelte-1.0.0-py3-none-any.whl size=155127 sha256=75a2ae9dec36bc8d19be523f2bf4a687827bd09b23259e59be06bbbb76aac343\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rvt_g_u3/wheels/8b/3d/d6/06740af14f32f538ea224dc82253ef4ba35186e814d6e4f0a4\n",
            "Successfully built PySvelte\n",
            "Installing collected packages: PySvelte\n",
            "Successfully installed PySvelte-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6913bc8b-6a29-4ad8-b1f2-68732d62d3ba"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import einops\n",
        "from tqdm.notebook import tqdm, trange\n",
        "\n",
        "import random\n",
        "import time\n",
        "\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from functools import *\n",
        "import pandas as pd\n",
        "import gc\n",
        "\n",
        "# import comet_ml\n",
        "import itertools\n",
        "import tqdm.notebook as tq\n",
        "\n"
      ],
      "id": "6913bc8b-6a29-4ad8-b1f2-68732d62d3ba"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32MrE1aMrRw2"
      },
      "outputs": [],
      "source": [
        "assert torch.cuda.is_available()"
      ],
      "id": "32MrE1aMrRw2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50c5be68-66e4-4459-9fc4-166300eb859d"
      },
      "outputs": [],
      "source": [
        "# A helper class to get access to intermediate activations (inspired by Garcon)\n",
        "# It's a dummy module that is the identity function by default\n",
        "# I can wrap any intermediate activation in a HookPoint and get a convenient \n",
        "# way to add PyTorch hooks\n",
        "\n",
        "# Copied shamelessly from Neel Nanda\n",
        "\n",
        "class HookPoint(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fwd_hooks = []\n",
        "        self.bwd_hooks = []\n",
        "    \n",
        "    def give_name(self, name):\n",
        "        # Called by the model at initialisation\n",
        "        self.name = name\n",
        "    \n",
        "    def add_hook(self, hook, dir='fwd'):\n",
        "        # Hook format is fn(activation, hook_name)\n",
        "        # Change it into PyTorch hook format (this includes input and output, \n",
        "        # which are the same for a HookPoint)\n",
        "        def full_hook(module, module_input, module_output):\n",
        "            return hook(module_output, name=self.name)\n",
        "        if dir=='fwd':\n",
        "            handle = self.register_forward_hook(full_hook)\n",
        "            self.fwd_hooks.append(handle)\n",
        "        elif dir=='bwd':\n",
        "            handle = self.register_backward_hook(full_hook)\n",
        "            self.bwd_hooks.append(handle)\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid direction {dir}\")\n",
        "    \n",
        "    def remove_hooks(self, dir='fwd'):\n",
        "        if (dir=='fwd') or (dir=='both'):\n",
        "            for hook in self.fwd_hooks:\n",
        "                hook.remove()\n",
        "            self.fwd_hooks = []\n",
        "        if (dir=='bwd') or (dir=='both'):\n",
        "            for hook in self.bwd_hooks:\n",
        "                hook.remove()\n",
        "            self.bwd_hooks = []\n",
        "        if dir not in ['fwd', 'bwd', 'both']:\n",
        "            raise ValueError(f\"Invalid direction {dir}\")\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return x\n",
        "    \n"
      ],
      "id": "50c5be68-66e4-4459-9fc4-166300eb859d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bb4890a-0e62-46df-988a-e0e11921f09b"
      },
      "outputs": [],
      "source": [
        "# Define network architecture\n",
        "# I defined my own transformer from scratch so I'd fully understand each component \n",
        "# - I expect this wasn't necessary or particularly important, and a bunch of this \n",
        "# replicates existing PyTorch functionality\n",
        "\n",
        "# Copied shamelessly from Neel Nanda\n",
        "\n",
        "# Embed & Unembed\n",
        "class Embed(nn.Module):\n",
        "    def __init__(self, d_vocab, d_model):\n",
        "        super().__init__()\n",
        "        self.W_E = nn.Parameter(torch.randn(d_model, d_vocab)/np.sqrt(d_model))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return torch.einsum('dbp -> bpd', self.W_E[:, x])\n",
        "\n",
        "class Unembed(nn.Module):\n",
        "    def __init__(self, d_vocab, d_model):\n",
        "        super().__init__()\n",
        "        self.W_U = nn.Parameter(torch.randn(d_model, d_vocab)/np.sqrt(d_vocab))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return (x @ self.W_U)\n",
        "\n",
        "# Positional Embeddings\n",
        "class PosEmbed(nn.Module):\n",
        "    def __init__(self, max_ctx, d_model):\n",
        "        super().__init__()\n",
        "        self.W_pos = nn.Parameter(torch.randn(max_ctx, d_model)/np.sqrt(d_model))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return x+self.W_pos[:x.shape[-2]]\n",
        "\n",
        "# LayerNorm\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, d_model, epsilon = 1e-4, model=[None]):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.w_ln = nn.Parameter(torch.ones(d_model))\n",
        "        self.b_ln = nn.Parameter(torch.zeros(d_model))\n",
        "        self.epsilon = epsilon\n",
        "    \n",
        "    def forward(self, x):\n",
        "        if self.model[0].use_ln:\n",
        "            x = x - x.mean(axis=-1)[..., None]\n",
        "            x = x / (x.std(axis=-1)[..., None] + self.epsilon)\n",
        "            x = x * self.w_ln\n",
        "            x = x + self.b_ln\n",
        "            return x\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "# Attention\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_head, n_ctx, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.W_K = nn.Parameter(torch.randn(num_heads, d_head, d_model)/np.sqrt(d_model))\n",
        "        self.W_Q = nn.Parameter(torch.randn(num_heads, d_head, d_model)/np.sqrt(d_model))\n",
        "        self.W_V = nn.Parameter(torch.randn(num_heads, d_head, d_model)/np.sqrt(d_model))\n",
        "        self.W_O = nn.Parameter(torch.randn(d_model, d_head * num_heads)/np.sqrt(d_model))\n",
        "        self.register_buffer('mask', torch.tril(torch.ones((n_ctx, n_ctx))))\n",
        "        self.d_head = d_head\n",
        "        self.hook_k = HookPoint()\n",
        "        self.hook_q = HookPoint()\n",
        "        self.hook_v = HookPoint()\n",
        "        self.hook_z = HookPoint()\n",
        "        self.hook_attn = HookPoint()\n",
        "        self.hook_attn_pre = HookPoint()\n",
        "\n",
        "    def forward(self, x):\n",
        "        k = self.hook_k(torch.einsum('ihd,bpd->biph', self.W_K, x))\n",
        "        q = self.hook_q(torch.einsum('ihd,bpd->biph', self.W_Q, x))\n",
        "        v = self.hook_v(torch.einsum('ihd,bpd->biph', self.W_V, x))\n",
        "        attn_scores_pre = torch.einsum('biph,biqh->biqp', k, q)\n",
        "        attn_scores_masked = torch.tril(attn_scores_pre) - 1e10 * (1 - self.mask[:x.shape[-2], :x.shape[-2]])\n",
        "        attn_matrix = self.hook_attn(F.softmax(self.hook_attn_pre(attn_scores_masked/np.sqrt(self.d_head)), dim=-1))\n",
        "        z = self.hook_z(torch.einsum('biph,biqp->biqh', v, attn_matrix))\n",
        "        z_flat = einops.rearrange(z, 'b i q h -> b q (i h)')\n",
        "        out = torch.einsum('df,bqf->bqd', self.W_O, z_flat)\n",
        "        return out\n",
        "\n",
        "# MLP Layers\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, d_model, d_mlp, act_type, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.W_in = nn.Parameter(torch.randn(d_mlp, d_model)/np.sqrt(d_model))\n",
        "        self.b_in = nn.Parameter(torch.zeros(d_mlp))\n",
        "        self.W_out = nn.Parameter(torch.randn(d_model, d_mlp)/np.sqrt(d_model))\n",
        "        self.b_out = nn.Parameter(torch.zeros(d_model))\n",
        "        self.act_type = act_type\n",
        "        # self.ln = LayerNorm(d_mlp, model=self.model)\n",
        "        self.hook_pre = HookPoint()\n",
        "        self.hook_post = HookPoint()\n",
        "        assert act_type in ['ReLU', 'GeLU']\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.hook_pre(torch.einsum('md,bpd->bpm', self.W_in, x) + self.b_in)\n",
        "        if self.act_type=='ReLU':\n",
        "            x = F.relu(x)\n",
        "        elif self.act_type=='GeLU':\n",
        "            x = F.gelu(x)\n",
        "        x = self.hook_post(x)\n",
        "        x = torch.einsum('dm,bpm->bpd', self.W_out, x) + self.b_out\n",
        "        return x\n",
        "\n",
        "# Transformer Block\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, d_model, d_mlp, d_head, num_heads, n_ctx, act_type, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        # self.ln1 = LayerNorm(d_model, model=self.model)\n",
        "        self.attn = Attention(d_model, num_heads, d_head, n_ctx, model=self.model)\n",
        "        # self.ln2 = LayerNorm(d_model, model=self.model)\n",
        "        self.mlp = MLP(d_model, d_mlp, act_type, model=self.model)\n",
        "        self.hook_attn_out = HookPoint()\n",
        "        self.hook_mlp_out = HookPoint()\n",
        "        self.hook_resid_pre = HookPoint()\n",
        "        self.hook_resid_mid = HookPoint()\n",
        "        self.hook_resid_post = HookPoint()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.hook_resid_mid(x + self.hook_attn_out(self.attn((self.hook_resid_pre(x)))))\n",
        "        x = self.hook_resid_post(x + self.hook_mlp_out(self.mlp((x))))\n",
        "        return x\n",
        "\n",
        "# Full transformer\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, num_layers, d_vocab, d_model, d_mlp, d_head, num_heads, n_ctx, act_type, use_cache=False, use_ln=True):\n",
        "        super().__init__()\n",
        "        self.cache = {}\n",
        "        self.use_cache = use_cache\n",
        "\n",
        "        self.embed = Embed(d_vocab, d_model)\n",
        "        self.pos_embed = PosEmbed(n_ctx, d_model)\n",
        "        self.blocks = nn.ModuleList([TransformerBlock(d_model, d_mlp, d_head, num_heads, n_ctx, act_type, model=[self]) for i in range(num_layers)])\n",
        "        # self.ln = LayerNorm(d_model, model=[self])\n",
        "        self.unembed = Unembed(d_vocab, d_model)\n",
        "        self.use_ln = use_ln\n",
        "\n",
        "        for name, module in self.named_modules():\n",
        "            if type(module)==HookPoint:\n",
        "                module.give_name(name)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)\n",
        "        x = self.pos_embed(x)\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        # x = self.ln(x)\n",
        "        x = self.unembed(x)\n",
        "        return x\n",
        "\n",
        "    def set_use_cache(self, use_cache):\n",
        "        self.use_cache = use_cache\n",
        "    \n",
        "    def hook_points(self):\n",
        "        return [module for name, module in self.named_modules() if 'hook' in name]\n",
        "\n",
        "    def remove_all_hooks(self):\n",
        "        for hp in self.hook_points():\n",
        "            hp.remove_hooks('fwd')\n",
        "            hp.remove_hooks('bwd')\n",
        "    \n",
        "    def cache_all(self, cache, incl_bwd=False):\n",
        "        # Caches all activations wrapped in a HookPoint\n",
        "        def save_hook(tensor, name):\n",
        "            cache[name] = tensor.detach()\n",
        "        def save_hook_back(tensor, name):\n",
        "            cache[name+'_grad'] = tensor[0].detach()\n",
        "        for hp in self.hook_points():\n",
        "            hp.add_hook(save_hook, 'fwd')\n",
        "            if incl_bwd:\n",
        "                hp.add_hook(save_hook_back, 'bwd')"
      ],
      "id": "2bb4890a-0e62-46df-988a-e0e11921f09b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bda4fe3-d38b-470c-b46b-9d7ff65b2ff7"
      },
      "outputs": [],
      "source": [
        "lr=1e-3\n",
        "weight_decay = 1.0\n",
        "p=53\n",
        "d_model = 256\n",
        "fn_name = 'x^y+z'\n",
        "frac_train = 0.5\n",
        "num_epochs = 50_000\n",
        "save_models = True\n",
        "save_every = 100\n",
        "# Stop training when test loss is <stopping_thresh\n",
        "stopping_thresh = -1\n",
        "seed = 0 \n",
        "\n",
        "num_layers = 1\n",
        "batch_style = 'full'\n",
        "d_vocab = p\n",
        "n_ctx = 3\n",
        "d_mlp = 4*d_model\n",
        "num_heads = 4\n",
        "assert d_model % num_heads == 0\n",
        "d_head = d_model//num_heads\n",
        "act_type = 'ReLU' \n",
        "batch_size = 512\n",
        "use_ln = False\n",
        "#random_answers = np.random.randint(low=0, high=p, size=(p, p))\n",
        "fns_dict = {\n",
        "    'add': lambda x,y:(x+y)%p,\n",
        "    'subtract': lambda x,y:(x-y)%p,\n",
        "    'x2xyy2':lambda x,y:(x**2+x*y+y**2)%p,\n",
        "    'x*y+z': lambda x, y, z: ((x*y)+z)%p,\n",
        "    'x^y+z': lambda x, y, z: ((x**y)+z)%p\n",
        "    \n",
        "}\n",
        "fn = fns_dict[fn_name]"
      ],
      "id": "8bda4fe3-d38b-470c-b46b-9d7ff65b2ff7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nD3cSkDrapU"
      },
      "outputs": [],
      "source": [
        "import polars as pl\n",
        "\n",
        "class FiniteFieldPoly(Dataset):\n",
        "\n",
        "    def __init__(self, p: int, data):\n",
        "        self.p = p\n",
        "        self.data = data\n",
        "\n",
        "\n",
        "    def poly(self, x, y, z):\n",
        "        return (x ** y + z) % self.p\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        x, y, z = self.data[i]\n",
        "        val = torch.tensor(self.poly(x, y, z))\n",
        "        data = torch.tensor([x, y, z]\n",
        "        )\n",
        "        return data, val\n",
        "\n",
        "    @classmethod\n",
        "    def make_train_test(cls, p: int, frac_train: float, seed: int = 0):\n",
        "        all_data = [\n",
        "            (i, j, k) for i in range(p) for j in range(p) for k in range(p)\n",
        "        ]\n",
        "        all_data = pl.Series('triple', all_data).shuffle(seed=seed).to_list()\n",
        "        #random.shuffle(all_data)\n",
        "        div = int(frac_train*len(all_data))\n",
        "        train, test = all_data[:div], all_data[div:]\n",
        "        return cls(p, train), cls(p, test)\n",
        "\n",
        "\n"
      ],
      "id": "5nD3cSkDrapU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4hO_mrgRZrp"
      },
      "outputs": [],
      "source": [
        "train, test = FiniteFieldPoly.make_train_test(p, frac_train, seed=0)"
      ],
      "id": "Q4hO_mrgRZrp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XEuPoxlhbDY",
        "outputId": "232b637f-4b29-43e1-fec1-ce85721675ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "3XEuPoxlhbDY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97bf5364-27c4-4b2f-b29c-33a597d96357"
      },
      "outputs": [],
      "source": [
        "root = Path('/content/drive/MyDrive/exponential_grokking')\n"
      ],
      "id": "97bf5364-27c4-4b2f-b29c-33a597d96357"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa1dfbbc-d3cb-4a3c-968b-040bf9ab12fe"
      },
      "outputs": [],
      "source": [
        "# Helper functions\n",
        "def cuda_memory():\n",
        "    print(torch.cuda.memory_allocated()/1e9)\n",
        "\n",
        "def cross_entropy_high_precision(logits, labels):\n",
        "    # Shapes: batch x vocab, batch\n",
        "    # Cast logits to float64 because log_softmax has a float32 underflow on overly \n",
        "    # confident data and can only return multiples of 1.2e-7 (the smallest float x\n",
        "    # such that 1+x is different from 1 in float32). This leads to loss spikes \n",
        "    # and dodgy gradients\n",
        "    logprobs = F.log_softmax(logits.to(torch.float64), dim=-1)\n",
        "    prediction_logprobs = torch.gather(logprobs, index=labels[:, None], dim=-1)\n",
        "    loss = -torch.mean(prediction_logprobs)\n",
        "    return loss\n",
        "\n",
        "#def full_loss(model, data):\n",
        "#    # Take the final position only\n",
        "#    logits = model(data)[:, -1]\n",
        "#    labels = torch.tensor([fn(i, j, k) for i, x, j, y, k, _ in data]).to('cuda')\n",
        "#    return cross_entropy_high_precision(logits, labels)\n",
        "\n",
        "\n",
        "def full_loss(model, equations, labels):\n",
        "    logits = model(equations)[:, -1]\n",
        "    return cross_entropy_high_precision(logits, labels)\n",
        "    \n",
        "\n",
        "def test_logits(logits, bias_correction=False, original_logits=None, mode='all'):\n",
        "    # Calculates cross entropy loss of logits representing a batch of all p^2 \n",
        "    # possible inputs\n",
        "    # Batch dimension is assumed to be first\n",
        "    if logits.shape[1]==p*p:\n",
        "        logits = logits.T\n",
        "    if logits.shape==torch.Size([p*p, p+1]):\n",
        "        logits = logits[:, :-1]\n",
        "    logits = logits.reshape(p*p, p)\n",
        "    if bias_correction:\n",
        "        # Applies bias correction - we correct for any missing bias terms, \n",
        "        # independent of the input, by centering the new logits along the batch \n",
        "        # dimension, and then adding the average original logits across all inputs\n",
        "        logits = einops.reduce(original_logits - logits, 'batch ... -> ...', 'mean') + logits\n",
        "    if mode=='train':\n",
        "        return cross_entropy_high_precision(logits[is_train], labels[is_train])\n",
        "    elif mode=='test':\n",
        "        return cross_entropy_high_precision(logits[is_test], labels[is_test])\n",
        "    elif mode=='all':\n",
        "        return cross_entropy_high_precision(logits, labels)"
      ],
      "id": "fa1dfbbc-d3cb-4a3c-968b-040bf9ab12fe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04dv7vRoTZav"
      },
      "outputs": [],
      "source": [
        "def full_forward_pass(model, data_loader):\n",
        "    epoch_loss = torch.tensor(0., device='cuda')\n",
        "    for batch_poly, batch_labels in data_loader:\n",
        "        loss = full_loss(model, batch_poly.to('cuda'), batch_labels.to('cuda'))\n",
        "        epoch_loss += loss\n",
        "    return epoch_loss"
      ],
      "id": "04dv7vRoTZav"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJruuCA4S-bn"
      },
      "outputs": [],
      "source": [
        "batch_size = 2 ** 14 # 16_384\n",
        "train_loader = DataLoader(train, batch_size, shuffle=False, num_workers=2, pin_memory=True, drop_last=False)\n",
        "test_loader = DataLoader(test, batch_size, shuffle=False, num_workers=2, pin_memory=True, drop_last=False)"
      ],
      "id": "fJruuCA4S-bn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a48c9828-cf2d-4ca1-96fc-a563105a7974",
        "outputId": "7d4f1055-bcec-49cd-b6d6-5840e50c8794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run name grok_1671590348\n"
          ]
        }
      ],
      "source": [
        "model = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_vocab=d_vocab,\n",
        "    d_model=d_model,\n",
        "    d_mlp=d_mlp,\n",
        "    d_head=d_head,\n",
        "    num_heads=num_heads,\n",
        "    n_ctx=n_ctx,\n",
        "    act_type=act_type,\n",
        "    use_cache=False,\n",
        "    use_ln=use_ln\n",
        ")\n",
        "model.to('cuda')\n",
        "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay, betas=(0.9, 0.98))\n",
        "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lambda step: min(step/10, 1))\n",
        "run_name = f\"grok_{int(time.time())}\"\n",
        "print(f'Run name {run_name}')\n",
        "if save_models:\n",
        "    os.mkdir(root/run_name)\n",
        "    save_dict = {'model':model.state_dict(), 'train_data':train, 'test_data':test}\n",
        "    torch.save(save_dict, root/run_name/'init.pth')\n"
      ],
      "id": "a48c9828-cf2d-4ca1-96fc-a563105a7974"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e9fed6fce8da47e29b24188ab632b075",
            "35e7e76467074f85a18f5a3340a46da4",
            "d1694369d5e14fe5a7135b96d0d00892",
            "0af9807804ca42c49800e7fe0c86beca",
            "29c1114c48c34fb19ca0706b44b2f61a",
            "35e9a3592c1f44bab5d2e057feda33f6",
            "560eb9f59191472ab1915e7c2861b971",
            "94f866befcdb406bb88cfbb24fba4ef4",
            "c16add8643bc421599525cbcc1e703d0",
            "7ce73ccec9e54bf4937bf85967b2e763",
            "08034cd674b246fc880915b0566406d4"
          ]
        },
        "id": "2hdxy0ZjS8XW",
        "outputId": "3c15f495-58ad-4445-d679-d086c721cbbe"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9fed6fce8da47e29b24188ab632b075",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/50000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 || 3.0066 || 3.0070\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/0.pth\n",
            "Epoch 100 || 2.5817 || 2.6289\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/100.pth\n",
            "Epoch 200 || 2.4413 || 2.5258\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/200.pth\n",
            "Epoch 300 || 2.3944 || 2.5085\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/300.pth\n",
            "Epoch 400 || 2.3813 || 2.5204\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/400.pth\n",
            "Epoch 500 || 2.3608 || 2.5301\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/500.pth\n",
            "Epoch 600 || 2.3495 || 2.5469\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/600.pth\n",
            "Epoch 700 || 2.3289 || 2.5605\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/700.pth\n",
            "Epoch 800 || 2.3167 || 2.5784\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/800.pth\n",
            "Epoch 900 || 2.2853 || 2.5864\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/900.pth\n",
            "Epoch 1000 || 2.2905 || 2.6145\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/1000.pth\n",
            "Epoch 1100 || 2.2344 || 2.5981\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/1100.pth\n",
            "Epoch 1200 || 2.2221 || 2.6252\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/1200.pth\n",
            "Epoch 1300 || 2.1502 || 2.6004\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/1300.pth\n",
            "Epoch 1400 || 2.1020 || 2.5926\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/1400.pth\n",
            "Epoch 1500 || 2.0666 || 2.5973\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/1500.pth\n",
            "Epoch 1600 || 1.9586 || 2.5485\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/1600.pth\n",
            "Epoch 1700 || 1.8800 || 2.5160\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/1700.pth\n",
            "Epoch 1800 || 1.7781 || 2.4683\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/1800.pth\n",
            "Epoch 1900 || 1.6402 || 2.3961\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/1900.pth\n",
            "Epoch 2000 || 1.5429 || 2.3455\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/2000.pth\n",
            "Epoch 2100 || 1.3907 || 2.2601\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/2100.pth\n",
            "Epoch 2200 || 1.2815 || 2.2072\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/2200.pth\n",
            "Epoch 2300 || 1.1651 || 2.1298\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/2300.pth\n",
            "Epoch 2400 || 1.0914 || 2.0653\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/2400.pth\n",
            "Epoch 2500 || 1.1010 || 2.0238\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/2500.pth\n",
            "Epoch 2600 || 0.9267 || 1.9100\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/2600.pth\n",
            "Epoch 2700 || 0.8171 || 1.8339\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/2700.pth\n",
            "Epoch 2800 || 1.2404 || 2.0127\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/2800.pth\n",
            "Epoch 2900 || 1.1466 || 1.9298\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/2900.pth\n",
            "Epoch 3000 || 0.8893 || 1.7812\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/3000.pth\n",
            "Epoch 3100 || 0.7177 || 1.6809\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/3100.pth\n",
            "Epoch 3200 || 0.6747 || 1.6436\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/3200.pth\n",
            "Epoch 3300 || 0.1923 || 1.4375\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/3300.pth\n",
            "Epoch 3400 || 0.3489 || 1.3884\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/3400.pth\n",
            "Epoch 3500 || -0.0105 || 1.3262\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/3500.pth\n",
            "Epoch 3600 || 0.1741 || 1.2960\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/3600.pth\n",
            "Epoch 3700 || 0.5506 || 1.5304\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/3700.pth\n",
            "Epoch 3800 || -0.2347 || 1.2127\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/3800.pth\n",
            "Epoch 3900 || -0.1310 || 1.1888\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/3900.pth\n",
            "Epoch 4000 || -0.6067 || 1.1812\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/4000.pth\n",
            "Epoch 4100 || -0.1583 || 1.1509\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/4100.pth\n",
            "Epoch 4200 || -0.5521 || 1.1183\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/4200.pth\n",
            "Epoch 4300 || -0.1625 || 1.1193\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/4300.pth\n",
            "Epoch 4400 || -0.3680 || 1.0710\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/4400.pth\n",
            "Epoch 4500 || 0.3299 || 1.3588\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/4500.pth\n",
            "Epoch 4600 || -0.2741 || 1.0393\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/4600.pth\n",
            "Epoch 4700 || -0.9162 || 1.0034\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/4700.pth\n",
            "Epoch 4800 || -0.3164 || 1.0010\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/4800.pth\n",
            "Epoch 4900 || -0.6932 || 0.9434\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/4900.pth\n",
            "Epoch 5000 || -0.2493 || 1.0639\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/5000.pth\n",
            "Epoch 5100 || -0.4872 || 0.9133\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/5100.pth\n",
            "Epoch 5200 || -1.2352 || 0.8594\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/5200.pth\n",
            "Epoch 5300 || -0.3523 || 0.9374\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/5300.pth\n",
            "Epoch 5400 || -0.3486 || 0.8739\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/5400.pth\n",
            "Epoch 5500 || -1.0848 || 0.7766\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/5500.pth\n",
            "Epoch 5600 || 0.5948 || 1.4358\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/5600.pth\n",
            "Epoch 5700 || -0.5050 || 0.7872\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/5700.pth\n",
            "Epoch 5800 || -1.0879 || 0.6694\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/5800.pth\n",
            "Epoch 5900 || 0.8124 || 1.4989\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/5900.pth\n",
            "Epoch 6000 || -0.5466 || 0.7125\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/6000.pth\n",
            "Epoch 6100 || -1.1833 || 0.5682\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/6100.pth\n",
            "Epoch 6200 || 2.5938 || 2.8113\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/6200.pth\n",
            "Epoch 6300 || -0.4729 || 0.6806\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/6300.pth\n",
            "Epoch 6400 || -0.8536 || 0.5482\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/6400.pth\n",
            "Epoch 6500 || -1.8824 || 0.3663\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/6500.pth\n",
            "Epoch 6600 || 0.6693 || 1.3821\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/6600.pth\n",
            "Epoch 6700 || -0.6054 || 0.5524\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/6700.pth\n",
            "Epoch 6800 || -1.1170 || 0.3654\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/6800.pth\n",
            "Epoch 6900 || -2.1987 || 0.1240\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/6900.pth\n",
            "Epoch 7000 || -1.2077 || 0.3070\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/7000.pth\n",
            "Epoch 7100 || -1.1312 || 0.2543\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/7100.pth\n",
            "Epoch 7200 || -2.0873 || -0.0056\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/7200.pth\n",
            "Epoch 7300 || -3.2145 || -0.2175\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/7300.pth\n",
            "Epoch 7400 || 2.5812 || 2.7971\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/7400.pth\n",
            "Epoch 7500 || -1.1174 || 0.1500\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/7500.pth\n",
            "Epoch 7600 || -1.1086 || 0.1128\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/7600.pth\n",
            "Epoch 7700 || -2.1093 || -0.2365\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/7700.pth\n",
            "Epoch 7800 || -3.2181 || -0.4985\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/7800.pth\n",
            "Epoch 7900 || 0.1480 || 0.9469\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/7900.pth\n",
            "Epoch 8000 || -0.7970 || 0.1856\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/8000.pth\n",
            "Epoch 8100 || -1.1742 || -0.0167\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/8100.pth\n",
            "Epoch 8200 || -2.2315 || -0.4215\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/8200.pth\n",
            "Epoch 8300 || -3.3187 || -0.7041\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/8300.pth\n",
            "Epoch 8400 || -4.3882 || -0.8999\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/8400.pth\n",
            "Epoch 8500 || -1.4555 || -0.1461\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/8500.pth\n",
            "Epoch 8600 || -0.8140 || 0.0811\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/8600.pth\n",
            "Epoch 8700 || -1.5705 || -0.2922\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/8700.pth\n",
            "Epoch 8800 || -2.6555 || -0.7029\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/8800.pth\n",
            "Epoch 8900 || -3.7471 || -0.9904\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/8900.pth\n",
            "Epoch 9000 || -4.7817 || -1.1983\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/9000.pth\n",
            "Epoch 9100 || -5.8336 || -1.3448\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/9100.pth\n",
            "Epoch 9200 || -1.9687 || -0.4363\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/9200.pth\n",
            "Epoch 9300 || -1.1199 || -0.1674\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/9300.pth\n",
            "Epoch 9400 || -1.7956 || -0.5110\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/9400.pth\n",
            "Epoch 9500 || -2.8680 || -0.9403\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/9500.pth\n",
            "Epoch 9600 || -3.9541 || -1.2583\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/9600.pth\n",
            "Epoch 9700 || 3.4647 || 3.5327\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/9700.pth\n",
            "Epoch 9800 || -1.2547 || -0.2539\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/9800.pth\n",
            "Epoch 9900 || -1.1817 || -0.2543\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/9900.pth\n",
            "Epoch 10000 || -2.1731 || -0.7573\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/10000.pth\n",
            "Epoch 10100 || -3.2643 || -1.1920\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/10100.pth\n",
            "Epoch 10200 || -4.3528 || -1.5122\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/10200.pth\n",
            "Epoch 10300 || -5.3372 || -1.7219\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/10300.pth\n",
            "Epoch 10400 || -1.5139 || -0.4381\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/10400.pth\n",
            "Epoch 10500 || -1.1785 || -0.3070\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/10500.pth\n",
            "Epoch 10600 || -2.1073 || -0.8084\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/10600.pth\n",
            "Epoch 10700 || -3.1887 || -1.2808\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/10700.pth\n",
            "Epoch 10800 || -4.2726 || -1.6386\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/10800.pth\n",
            "Epoch 10900 || -5.3453 || -1.9019\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/10900.pth\n",
            "Epoch 11000 || -1.8649 || -0.6119\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/11000.pth\n",
            "Epoch 11100 || -1.1382 || -0.3226\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/11100.pth\n",
            "Epoch 11200 || -1.8966 || -0.7586\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/11200.pth\n",
            "Epoch 11300 || -2.9713 || -1.2736\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/11300.pth\n",
            "Epoch 11400 || -4.0528 || -1.6814\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/11400.pth\n",
            "Epoch 11500 || -5.1293 || -1.9865\n",
            "Saved model to /content/drive/MyDrive/exponential_grokking/grok_1671590348/11500.pth\n"
          ]
        }
      ],
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "train_model = True\n",
        "if train_model:\n",
        "    for epoch in trange(num_epochs):\n",
        "        train_loss = full_forward_pass(model, train_loader)\n",
        "        with torch.no_grad():\n",
        "            test_loss = full_forward_pass(model, test_loader)\n",
        "        train_losses.append(train_loss.item())\n",
        "        test_losses.append(test_loss.item())\n",
        "        if epoch % 100 == 0:\n",
        "            logtrain = np.log(train_loss.item())\n",
        "            logtest = np.log(test_loss.item())\n",
        "            print(f\"Epoch {epoch} || {logtrain:.4f} || {logtest:.4f}\")\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        if test_loss.item() < stopping_thresh:\n",
        "            break\n",
        "        if (save_models) and (epoch%save_every == 0):\n",
        "            if test_loss.item() < stopping_thresh:\n",
        "                break\n",
        "            save_dict = {\n",
        "                'model': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'scheduler': scheduler.state_dict(),\n",
        "                'train_loss': train_loss,\n",
        "                'test_loss': test_loss,\n",
        "                'epoch': epoch,\n",
        "            }\n",
        "            torch.save(save_dict, root/run_name/f\"{epoch}.pth\")\n",
        "            print(f\"Saved model to {root/run_name/f'{epoch}.pth'}\")\n",
        "        del train_loss\n",
        "    if not save_models:\n",
        "        os.mkdir(root/run_name)\n",
        "    save_dict = {\n",
        "        'model': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'scheduler': scheduler.state_dict(),\n",
        "        'train_loss': train_loss,\n",
        "        'test_loss': test_loss,\n",
        "        'train_losses': train_losses,\n",
        "        'test_losses': test_losses,\n",
        "        'epoch': epoch,\n",
        "    }\n",
        "    torch.save(save_dict, root/run_name/f\"final.pth\")\n",
        "    print(f\"Saved model to {root/run_name/f'final.pth'}\")\n",
        "    #lines([train_losses, test_losses], labels=['train', 'test'], log_y=True)\n",
        "\n",
        "    # save_models = False"
      ],
      "id": "2hdxy0ZjS8XW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fd641814-7140-4609-80f3-ba5c11d4e8f3"
      },
      "outputs": [],
      "source": [],
      "id": "fd641814-7140-4609-80f3-ba5c11d4e8f3"
    },
    {
      "cell_type": "code",
      "source": [
        "model = Transformer(num_layers=num_layers, d_vocab=d_vocab, d_model=d_model, d_mlp=d_mlp, d_head=d_head, num_heads=num_heads, n_ctx=n_ctx, act_type=act_type, use_cache=False, use_ln=use_ln)\n",
        "model.to('cuda')\n",
        "model.load_state_dict(full_run_data['state_dicts'][400])"
      ],
      "metadata": {
        "id": "gJHetY7RgFHd"
      },
      "id": "gJHetY7RgFHd",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e9fed6fce8da47e29b24188ab632b075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35e7e76467074f85a18f5a3340a46da4",
              "IPY_MODEL_d1694369d5e14fe5a7135b96d0d00892",
              "IPY_MODEL_0af9807804ca42c49800e7fe0c86beca"
            ],
            "layout": "IPY_MODEL_29c1114c48c34fb19ca0706b44b2f61a"
          }
        },
        "35e7e76467074f85a18f5a3340a46da4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35e9a3592c1f44bab5d2e057feda33f6",
            "placeholder": "​",
            "style": "IPY_MODEL_560eb9f59191472ab1915e7c2861b971",
            "value": " 23%"
          }
        },
        "d1694369d5e14fe5a7135b96d0d00892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94f866befcdb406bb88cfbb24fba4ef4",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c16add8643bc421599525cbcc1e703d0",
            "value": 11504
          }
        },
        "0af9807804ca42c49800e7fe0c86beca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ce73ccec9e54bf4937bf85967b2e763",
            "placeholder": "​",
            "style": "IPY_MODEL_08034cd674b246fc880915b0566406d4",
            "value": " 11504/50000 [12:55:22&lt;44:31:54,  4.16s/it]"
          }
        },
        "29c1114c48c34fb19ca0706b44b2f61a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35e9a3592c1f44bab5d2e057feda33f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "560eb9f59191472ab1915e7c2861b971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94f866befcdb406bb88cfbb24fba4ef4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c16add8643bc421599525cbcc1e703d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ce73ccec9e54bf4937bf85967b2e763": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08034cd674b246fc880915b0566406d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}